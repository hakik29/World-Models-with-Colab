{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Config"
      ],
      "metadata": {
        "id": "p55eK-HHMiyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperParams:\n",
        "    vision = 'VAE'\n",
        "    memory = 'RNN'\n",
        "    controller = 'A3C'\n",
        "\n",
        "    extra = False\n",
        "    data_dir = 'datasets'\n",
        "    extra_dir = 'additional'\n",
        "    ckpt_dir = 'ckpt'\n",
        "\n",
        "    img_height = 96\n",
        "    img_width = 96\n",
        "    img_channels = 3\n",
        "\n",
        "    batch_size = 2 # actually batchsize * Seqlen\n",
        "    seq_len = 32\n",
        "\n",
        "    test_batch = 1\n",
        "    n_sample = 64\n",
        "\n",
        "    vsize = 128 # latent size of Vision\n",
        "    msize = 128 # size of Memory\n",
        "    asize = 3 # action size\n",
        "    rnn_hunits = 256\n",
        "    ctrl_hidden_dims = 512\n",
        "    log_interval = 5000\n",
        "    save_interval = 10000\n",
        "\n",
        "    use_binary_feature = False\n",
        "    score_cut = 300 # to save\n",
        "    save_start_score = 100\n",
        "\n",
        "    # Rollout\n",
        "    max_ep = 1000\n",
        "    n_rollout = 200\n",
        "    seed = 0\n",
        "\n",
        "    n_workers = 0\n",
        "\n",
        "class RNNHyperParams:\n",
        "    vision = 'VAE'\n",
        "    memory = 'RNN'\n",
        "\n",
        "    extra = False\n",
        "    data_dir = 'datasets'\n",
        "    extra_dir = 'additional'\n",
        "    ckpt_dir = 'ckpt'\n",
        "\n",
        "    img_height = 96\n",
        "    img_width = 96\n",
        "    img_channels = 3\n",
        "\n",
        "    batch_size = 1 # actually batchsize * Seqlen\n",
        "    test_batch = 1\n",
        "    seq_len = 32\n",
        "    n_sample = 64\n",
        "\n",
        "    vsize = 128 # latent size of Vision\n",
        "    msize = 128 # size of Memory\n",
        "    asize = 3 # action size\n",
        "    rnn_hunits = 256\n",
        "    log_interval = 1000\n",
        "    save_interval = 2000\n",
        "\n",
        "    max_step = 100000\n",
        "\n",
        "    n_workers = 0\n",
        "\n",
        "    seed = 0\n",
        "\n",
        "class VAEHyperParams:\n",
        "    vision = 'VAE'\n",
        "\n",
        "    extra = False\n",
        "    data_dir = 'datasets'\n",
        "    extra_dir = 'additional'\n",
        "    ckpt_dir = 'ckpt'\n",
        "\n",
        "    img_height = 96\n",
        "    img_width = 96\n",
        "    img_channels = 3\n",
        "\n",
        "    batch_size = 64 #\n",
        "    test_batch = 12\n",
        "    n_sample = 64\n",
        "\n",
        "    vsize = 128 # latent size of Vision\n",
        "    msize = 128 # size of Memory\n",
        "    asize = 3 # action size\n",
        "\n",
        "    log_interval = 5000\n",
        "    save_interval = 10000\n",
        "\n",
        "    max_step = 2000000\n",
        "\n",
        "    n_workers = 0"
      ],
      "metadata": {
        "id": "hjMjzo1V1AHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, glob\n",
        "from os.path import join, exists\n",
        "from os import mkdir, unlink, listdir, getpid, makedirs\n",
        "\n",
        "import numpy as np\n",
        "import easydict\n",
        "import cma\n",
        "import gym\n",
        "from datetime import datetime\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.multiprocessing as multi\n",
        "from torch.nn import functional as F\n",
        "from torch.distributions.normal import Normal\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torch.multiprocessing import Process, Queue"
      ],
      "metadata": {
        "id": "fMMHGsgsIGk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp = HyperParams\n",
        "\n",
        "def rollout():\n",
        "    env = gym.make(\"CarRacing-v2\")\n",
        "\n",
        "    seq_len = 1000\n",
        "    max_ep = hp.n_rollout\n",
        "    feat_dir = hp.data_dir\n",
        "\n",
        "    os.makedirs(feat_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(max_ep):\n",
        "        obs_lst, action_lst, reward_lst, next_obs_lst, done_lst = [], [], [], [], []\n",
        "        env.reset()\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        done = False\n",
        "        t = 0\n",
        "\n",
        "        while not done or t < seq_len:\n",
        "            t += 1\n",
        "\n",
        "            action = env.action_space.sample()\n",
        "            next_obs, reward, done, _ = env.step(action)\n",
        "\n",
        "            np.savez(\n",
        "                os.path.join(feat_dir, 'rollout_{:03d}_{:04d}'.format(ep,t)),\n",
        "                obs=obs,\n",
        "                action=action,\n",
        "                reward=reward,\n",
        "                next_obs=next_obs,\n",
        "                done=done,\n",
        "            )\n",
        "\n",
        "            obs_lst.append(obs)\n",
        "            action_lst.append(action)\n",
        "            reward_lst.append(reward)\n",
        "            next_obs_lst.append(next_obs)\n",
        "            done_lst.append(done)\n",
        "            obs = next_obs\n",
        "        np.savez(\n",
        "            os.path.join(feat_dir, 'rollout_ep_{:03d}'.format(ep)),\n",
        "            obs=np.stack(obs_lst, axis=0), # (T, C, H, W)\n",
        "            action=np.stack(action_lst, axis=0), # (T, a)\n",
        "            reward=np.stack(reward_lst, axis=0), # (T, 1)\n",
        "            next_obs=np.stack(next_obs_lst, axis=0), # (T, C, H, W)\n",
        "            done=np.stack(done_lst, axis=0), # (T, 1)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    np.random.seed(hp.seed)\n",
        "    rollout()"
      ],
      "metadata": {
        "id": "q0rhvqjN05Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "class GameSceneDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, training=True, test_ratio=0.01):\n",
        "        self.fpaths = sorted(glob.glob(os.path.join(data_path, 'rollout_[0-9][0-9][0-9]_*.npz')))\n",
        "        np.random.seed(0)\n",
        "        indices = np.arange(0, len(self.fpaths))\n",
        "        n_trainset = int(len(indices)*(1.0-test_ratio))\n",
        "        self.train_indices = indices[:n_trainset]\n",
        "        self.test_indices = indices[n_trainset:]\n",
        "        # self.train_indices = np.random.choice(indices, int(len(indices)*(1.0-test_ratio)), replace=False)\n",
        "        # self.test_indices = np.delete(indices, self.train_indices)\n",
        "        self.indices = self.train_indices if training else self.test_indices\n",
        "        # import pdb; pdb.set_trace()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        npz = np.load(self.fpaths[self.indices[idx]])\n",
        "        obs = npz['obs']\n",
        "        obs = transform(obs)\n",
        "        # obs = obs.permute(2, 0, 1) # (N, C, H, W)\n",
        "        return obs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "class GameEpisodeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, seq_len=32, seq_mode=True, training=True, test_ratio=0.01):\n",
        "        self.training = training\n",
        "        self.fpaths = sorted(glob.glob(os.path.join(data_path, 'rollout_ep_*.npz')))\n",
        "        np.random.seed(0)\n",
        "        indices = np.arange(0, len(self.fpaths))\n",
        "        n_trainset = int(len(indices)*(1.0-test_ratio))\n",
        "        self.train_indices = indices[:n_trainset]\n",
        "        self.test_indices = indices[n_trainset:]\n",
        "        # self.train_indices = np.random.choice(indices, int(len(indices)*(1.0-test_ratio)), replace=False)\n",
        "        # self.test_indices = np.delete(indices, self.train_indices)\n",
        "        self.indices = self.train_indices if training else self.test_indices\n",
        "        self.seq_len = seq_len\n",
        "        self.seq_mode = seq_mode\n",
        "        # import pdb; pdb.set_trace()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        npz = np.load(self.fpaths[self.indices[idx]])\n",
        "        obs = npz['obs'] # (T, H, W, C) np array\n",
        "        actions = npz['action'] # (T, n_actions) np array\n",
        "        T, H, W, C = obs.shape\n",
        "        n_seq = T // self.seq_len\n",
        "        end_seq = n_seq * self.seq_len # T' = end of sequence\n",
        "\n",
        "        obs = obs[:end_seq].reshape([-1, self.seq_len, H, W, C]) # (N_seq, seq_len, H, W, C)\n",
        "        actions = actions[:end_seq].reshape([-1, self.seq_len, actions.shape[-1]]) #\n",
        "\n",
        "        # if args.seq_mode:\n",
        "        #     start_range = max_len-self.seq_len\n",
        "        #     for t in range(0, max_len-self.seq_len, self.seq_len):\n",
        "        #         obs[t:t+self.seq_len]\n",
        "        # else:\n",
        "        #     rand_start = np.random.randint(max_len-self.seq_len)\n",
        "        #     obs = obs[rand_start:rand_start+self.seq_len] # (T, H, W, C)\n",
        "        #     actions = actions[rand_start:rand_start+self.seq_len]\n",
        "        return obs, actions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "def collate_fn(data):\n",
        "    # obs (B, N_seq, seq_len, H, W, C), actions (B, N_seq, seq_len, n_actions)\n",
        "    obs, actions = zip(*data)\n",
        "    obs, actions = np.array(obs), np.array(actions)\n",
        "    _, _, seq_len, H, W, C = obs.shape\n",
        "    obs = obs.reshape([-1, H, W, C]) # (B*N_seq*seq_len, H, W, C)\n",
        "    actions = actions.reshape([-1, seq_len, actions.shape[-1]]) # (B*n_seq, n_actions)\n",
        "    obs_lst = []\n",
        "    for i in range(len(obs)): # batch loop\n",
        "        obs_lst.append(transform(obs[i]))\n",
        "        # for j in range(len(obs[i])): # sequence loop\n",
        "        #     obs_lst.append(transform(obs[i][j]))\n",
        "    obs = torch.stack(obs_lst, dim=0) # (B*N_seq*seq_len, C, H, W)\n",
        "    # obs = obs.view([-1, seq_len, H, W, C]) # (B*N_seq, seq_len, C, H, W)\n",
        "    return obs, torch.tensor(actions, dtype=torch.float)"
      ],
      "metadata": {
        "id": "94ELybwW1b6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VAE"
      ],
      "metadata": {
        "id": "7Nzximltg9wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp = HyperParams\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dims, img_channels=3):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(img_channels, latent_dims)\n",
        "        self.decoder = Decoder(img_channels, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        # sigma = logsigma.exp()\n",
        "        z = self.reparam(mu, logvar)\n",
        "        y = self.decoder(z)\n",
        "        return y, mu, logvar\n",
        "\n",
        "    def reparam(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.randn_like(std)\n",
        "        z = eps*std + mu\n",
        "        # z = eps*sigma + mu\n",
        "        return z\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        # flatten_dims = hp.img_height//2**4\n",
        "        self.latent_dims = latent_dims\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 32, 48, 48)\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 64, 24, 24)\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 128, 12, 12)\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 256, 6, 6)\n",
        "        )\n",
        "        self.fc = nn.Linear(6*6*256, latent_dims*2)\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(h.size(0), -1) # (B, d)\n",
        "        h = self.fc(h) # (B, )\n",
        "        mu = h[:, :self.latent_dims]\n",
        "        logvar = h[:, self.latent_dims:]\n",
        "        # sigma = self.softplus(h[:, self.latent_dims:])\n",
        "        return mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, out_channels, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc = nn.Linear(latent_dims, 1024)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 6, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 128, 6, 6)\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 64, 12, 12)\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 32, 24, 24)\n",
        "            nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(), # (B, 32, 48, 48)\n",
        "            nn.ConvTranspose2d(32, out_channels, 4, stride=2, padding=1),\n",
        "            # nn.Tanh()\n",
        "            nn.Sigmoid()\n",
        "            # nn.LeakyReLU(), # (B, c, 96, 96)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.fc(z)\n",
        "        h = h.view(h.size(0), -1, 2, 2)\n",
        "        y = self.decoder(h)\n",
        "        return y\n",
        "\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    \"\"\" VAE loss function \"\"\"\n",
        "    recon_loss = nn.MSELoss(size_average=False)\n",
        "    BCE = recon_loss(recon_x, x)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD, BCE, KLD"
      ],
      "metadata": {
        "id": "kbmQg8pg1m3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp = VAEHyperParams\n",
        "\n",
        "DEVICE = None\n",
        "\n",
        "def train():\n",
        "    global_step = 0\n",
        "    model = VAE(hp.vsize).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Loaded pretrained VAE\n",
        "    ckpts = sorted(glob.glob(os.path.join(hp.ckpt_dir, 'vae', '*k.pth.tar')))\n",
        "    if ckpts:\n",
        "        ckpt = ckpts[-1]\n",
        "        vae_state = torch.load(ckpt)\n",
        "        model.load_state_dict(vae_state['model'])\n",
        "        global_step = int(os.path.basename(ckpt).split('.')[0][:-1]) * 1000\n",
        "        print('Loaded vae ckpt {}'.format(ckpt))\n",
        "\n",
        "    data_path = hp.data_dir if not hp.extra else hp.extra_dir\n",
        "    dataset = GameSceneDataset(data_path)\n",
        "    loader = DataLoader(\n",
        "        dataset, batch_size=hp.batch_size, shuffle=True,\n",
        "        num_workers=hp.n_workers,\n",
        "    )\n",
        "    testset = GameSceneDataset(data_path, training=False)\n",
        "    test_loader = DataLoader(testset, batch_size=hp.test_batch, shuffle=False, drop_last=True)\n",
        "\n",
        "    ckpt_dir = os.path.join(hp.ckpt_dir, 'vae')\n",
        "    sample_dir = os.path.join(ckpt_dir, 'samples')\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    while global_step < hp.max_step:\n",
        "        for idx, obs in enumerate(tqdm(loader, total=len(loader))):\n",
        "            x = obs.to(DEVICE)\n",
        "            x_hat, mu, logvar = model(x)\n",
        "\n",
        "            loss, recon_loss, kld = vae_loss(x_hat, x, mu, logvar)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if global_step % hp.log_interval == 0:\n",
        "                recon_loss, kld = evaluate(test_loader, model, sample_dir, global_step)\n",
        "                now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                with open(os.path.join(ckpt_dir, 'train.log'), 'a') as f:\n",
        "                    log = '{} || Step: {}, loss: {:.4f}, kld: {:.4f}\\n'.format(now, global_step, recon_loss, kld)\n",
        "                    f.write(log)\n",
        "\n",
        "            if global_step % hp.save_interval == 0:\n",
        "                d = {\n",
        "                    'model': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }\n",
        "                torch.save(\n",
        "                    d, os.path.join(ckpt_dir, '{:03d}k.pth.tar'.format(global_step//1000))\n",
        "                )\n",
        "            global_step += 1\n",
        "\n",
        "def evaluate(test_loader, model, sample_dir=None, global_step=0):\n",
        "    model.eval()\n",
        "    total_recon_loss = []\n",
        "    total_kld_loss = []\n",
        "    n_sample = hp.n_sample\n",
        "    c_x = torch.zeros([n_sample, 3, 96, 96])\n",
        "    c_x_hat = torch.zeros([n_sample, 3, 96, 96])\n",
        "    with torch.no_grad():\n",
        "        for idx, obs in enumerate(test_loader):\n",
        "            x = obs.to(DEVICE)\n",
        "            # import pdb; pdb.set_trace()\n",
        "            x_hat, mu, logvar = model(x)\n",
        "            _, recon_loss, kld = vae_loss(x_hat, x, mu, logvar)\n",
        "\n",
        "            if idx < n_sample:\n",
        "                c_x[idx] = x[0]\n",
        "                c_x_hat[idx] = x_hat[0]\n",
        "            total_recon_loss.append(recon_loss.item())\n",
        "            total_kld_loss.append(kld.item())\n",
        "        z = torch.randn([n_sample, hp.vsize]).to(DEVICE)\n",
        "        x_rand = model.decoder(z)\n",
        "    save_image(x_rand, os.path.join(sample_dir, '{:04d}k-random.png'.format(global_step//1000)))\n",
        "    save_image(c_x_hat, os.path.join(sample_dir, '{:04d}k-xhat.png'.format(global_step//1000)))\n",
        "    save_image(c_x, os.path.join(sample_dir, '{:04d}k-x.png'.format(global_step//1000)))\n",
        "    model.train()\n",
        "    return np.mean(total_recon_loss), np.mean(total_kld_loss)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    train()"
      ],
      "metadata": {
        "id": "IB-uU4wI1zZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "_87V3ORfhDvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp = HyperParams\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, n_latents, n_actions, n_hiddens):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.LSTM(n_latents+n_actions, n_hiddens, batch_first=True)\n",
        "        # target --> next latent (vision)\n",
        "        self.fc = nn.Linear(n_hiddens, n_latents)\n",
        "\n",
        "    def forward(self, states):\n",
        "        h, _ = self.rnn(states)\n",
        "        y = self.fc(h)\n",
        "        return y, None, None\n",
        "\n",
        "    def infer(self, states, hidden):\n",
        "        h, next_hidden = self.rnn(states, hidden) # return (out, hx, cx)\n",
        "        y = self.fc(h)\n",
        "        return y, None, None, next_hidden"
      ],
      "metadata": {
        "id": "lJeprxUG19FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp = RNNHyperParams\n",
        "\n",
        "DEVICE = None\n",
        "\n",
        "def train():\n",
        "    global_step = 0\n",
        "\n",
        "    # Loaded pretrained VAE\n",
        "    vae = VAE(hp.vsize).to(DEVICE)\n",
        "    ckpt = sorted(glob.glob(os.path.join(hp.ckpt_dir, 'vae', '*k.pth.tar')))[-1]\n",
        "    vae_state = torch.load(ckpt)\n",
        "    vae.load_state_dict(vae_state['model'])\n",
        "    vae.eval()\n",
        "    print('Loaded vae ckpt {}'.format(ckpt))\n",
        "\n",
        "    rnn = RNN(hp.vsize, hp.asize, hp.rnn_hunits).to(DEVICE)\n",
        "    ckpts = sorted(glob.glob(os.path.join(hp.ckpt_dir, 'rnn', '*k.pth.tar')))\n",
        "    if ckpts:\n",
        "        ckpt = ckpts[-1]\n",
        "        rnn_state = torch.load(ckpt)\n",
        "        rnn.load_state_dict(rnn_state['model'])\n",
        "        global_step = int(os.path.basename(ckpt).split('.')[0][:-1]) * 1000\n",
        "        print('Loaded rnn ckpt {}'.format(ckpt))\n",
        "\n",
        "\n",
        "    data_path = hp.data_dir if not hp.extra else hp.extra_dir\n",
        "    # optimizer = torch.optim.RMSprop(rnn.parameters(), lr=1e-3)\n",
        "    optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-4)\n",
        "    dataset = GameEpisodeDataset(data_path, seq_len=hp.seq_len)\n",
        "    loader = DataLoader(\n",
        "        dataset, batch_size=1, shuffle=True, drop_last=True,\n",
        "        num_workers=hp.n_workers, collate_fn=collate_fn\n",
        "    )\n",
        "    testset = GameEpisodeDataset(data_path, seq_len=hp.seq_len, training=False)\n",
        "    test_loader = DataLoader(\n",
        "        testset, batch_size=1, shuffle=False, drop_last=False, collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    ckpt_dir = os.path.join(hp.ckpt_dir, 'rnn')\n",
        "    sample_dir = os.path.join(ckpt_dir, 'samples')\n",
        "    os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "    l1 = nn.L1Loss()\n",
        "\n",
        "    while global_step < hp.max_step:\n",
        "        # GO_states = torch.zeros([hp.batch_size, 1, hp.vsize+hp.asize]).to(DEVICE)\n",
        "        with tqdm(enumerate(loader), total=len(loader), ncols=70, leave=False) as t:\n",
        "            t.set_description('Step {}'.format(global_step))\n",
        "            for idx, (obs, actions) in t:\n",
        "                obs, actions = obs.to(DEVICE), actions.to(DEVICE)\n",
        "                with torch.no_grad():\n",
        "                    latent_mu, latent_var = vae.encoder(obs) # (B*T, vsize)\n",
        "                    z = latent_mu\n",
        "                    # z = vae.reparam(latent_mu, latent_var) # (B*T, vsize)\n",
        "                    z = z.view(-1, hp.seq_len, hp.vsize) # (B*n_seq, T, vsize)\n",
        "                # import pdb; pdb.set_trace()\n",
        "\n",
        "                next_z = z[:, 1:, :]\n",
        "                z, actions = z[:, :-1, :], actions[:, :-1, :]\n",
        "                states = torch.cat([z, actions], dim=-1) # (B, T, vsize+asize)\n",
        "                # states = torch.cat([GO_states, next_states[:,:-1,:]], dim=1)\n",
        "                x, _, _ = rnn(states)\n",
        "\n",
        "                loss = l1(x, next_z)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                global_step += 1\n",
        "\n",
        "                if global_step % hp.log_interval == 0:\n",
        "                    eval_loss = evaluate(test_loader, vae, rnn, global_step)\n",
        "                    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    with open(os.path.join(ckpt_dir, 'train.log'), 'a') as f:\n",
        "                        log = '{} || Step: {}, train_loss: {:.4f}, loss: {:.4f}\\n'.format(now, global_step, loss.item(), eval_loss)\n",
        "                        f.write(log)\n",
        "                    S = 2\n",
        "                    y = vae.decoder(x[S, :, :])\n",
        "                    v = vae.decoder(next_z[S, :, :])\n",
        "                    save_image(y, os.path.join(sample_dir, '{:04d}-rnn.png'.format(global_step)))\n",
        "                    save_image(v, os.path.join(sample_dir, '{:04d}-vae.png'.format(global_step)))\n",
        "                    save_image(obs[S:S+hp.seq_len-1], os.path.join(sample_dir, '{:04d}-obs.png'.format(global_step)))\n",
        "\n",
        "                if global_step % hp.save_interval == 0:\n",
        "                    d = {\n",
        "                        'model': rnn.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                    }\n",
        "                    torch.save(\n",
        "                        d, os.path.join(ckpt_dir, '{:03d}k.pth.tar'.format(global_step//1000))\n",
        "                    )\n",
        "\n",
        "def evaluate(test_loader, vae, rnn, global_step=0):\n",
        "    rnn.eval()\n",
        "    total_loss = []\n",
        "    l1 = nn.L1Loss()\n",
        "    with torch.no_grad():\n",
        "        for idx, (obs, actions) in enumerate(test_loader):\n",
        "            obs, actions = obs.to(DEVICE), actions.to(DEVICE)\n",
        "            latent_mu, latent_var = vae.encoder(obs) # (B*T, vsize)\n",
        "            z = latent_mu\n",
        "            # z = vae.reparam(latent_mu, latent_var) # (B*T, vsize)\n",
        "            z = z.view(-1, hp.seq_len, hp.vsize) # (B*n_seq, T, vsize)\n",
        "\n",
        "            next_z = z[:, 1:, :]\n",
        "            z, actions = z[:, :-1, :], actions[:, :-1, :]\n",
        "            states = torch.cat([z, actions], dim=-1) # (B, T, vsize+asize)\n",
        "            # states = torch.cat([GO_states, next_states[:,:-1,:]], dim=1)\n",
        "            x, _, _ = rnn(states)\n",
        "\n",
        "            loss = l1(x, next_z)\n",
        "\n",
        "            total_loss.append(loss.item())\n",
        "    rnn.train()\n",
        "    return np.mean(total_loss)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    np.random.seed(hp.seed)\n",
        "    train()"
      ],
      "metadata": {
        "id": "19S0Tbzt1-F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Controller"
      ],
      "metadata": {
        "id": "BY6JZSs8hofy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Define controller \"\"\"\n",
        "\n",
        "class Controller(nn.Module):\n",
        "    \"\"\" Controller \"\"\"\n",
        "    def __init__(self, latents, recurrents, actions):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latents + recurrents, actions)\n",
        "\n",
        "    def forward(self, *inputs):\n",
        "        cat_in = torch.cat(inputs, dim=1)\n",
        "        return self.fc(cat_in)"
      ],
      "metadata": {
        "id": "a_Q3DxDGjRwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_parameters(params):\n",
        "    \"\"\" Flattening parameters.\n",
        "\n",
        "    :args params: generator of parameters (as returned by module.parameters())\n",
        "\n",
        "    :returns: flattened parameters (i.e. one tensor of dimension 1 with all\n",
        "        parameters concatenated)\n",
        "    \"\"\"\n",
        "    return torch.cat([p.detach().view(-1) for p in params], dim=0).cpu().numpy()\n",
        "\n",
        "def unflatten_parameters(params, example, device):\n",
        "    \"\"\" Unflatten parameters.\n",
        "\n",
        "    :args params: parameters as a single 1D np array\n",
        "    :args example: generator of parameters (as returned by module.parameters()),\n",
        "        used to reshape params\n",
        "    :args device: where to store unflattened parameters\n",
        "\n",
        "    :returns: unflattened parameters\n",
        "    \"\"\"\n",
        "    params = torch.Tensor(params).to(device)\n",
        "    idx = 0\n",
        "    unflattened = []\n",
        "    for e_p in example:\n",
        "        unflattened += [params[idx:idx + e_p.numel()].view(e_p.size())]\n",
        "        idx += e_p.numel()\n",
        "    return unflattened\n",
        "\n",
        "def load_parameters(params, controller):\n",
        "    \"\"\" Load flattened parameters into controller.\n",
        "\n",
        "    :args params: parameters as a single 1D np array\n",
        "    :args controller: module in which params is loaded\n",
        "    \"\"\"\n",
        "    proto = next(controller.parameters())\n",
        "    params = unflatten_parameters(\n",
        "        params, controller.parameters(), proto.device)\n",
        "\n",
        "    for p, p_0 in zip(controller.parameters(), params):\n",
        "        p.data.copy_(p_0)"
      ],
      "metadata": {
        "id": "y5Vft5DG-3ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training a linear controller on latent + recurrent state\n",
        "with CMAES.\n",
        "\n",
        "This is a bit complex. num_workers slave threads are launched\n",
        "to process a queue filled with parameters to be evaluated.\n",
        "\"\"\"\n",
        "\n",
        "hp = HyperParams\n",
        "\n",
        "ctx = multi.get_context(\"spawn\")\n",
        "queue = ctx.Queue\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"logdir\" : 'ckpt',\n",
        "    \"n_samples\" : 4,\n",
        "    \"pop_size\" : 4,\n",
        "    \"target_return\" : 950,\n",
        "    \"display\" : True,\n",
        "    \"max_workers\" : 32\n",
        "})\n",
        "\n",
        "# multiprocessing variables\n",
        "n_samples = args.n_samples\n",
        "pop_size = args.pop_size\n",
        "num_workers = min(args.max_workers, n_samples * pop_size)\n",
        "time_limit = 1000\n",
        "\n",
        "\n",
        "# create tmp dir if non existent and clean it if existent\n",
        "tmp_dir = join(args.logdir, 'tmp')\n",
        "if not exists(tmp_dir):\n",
        "    makedirs(tmp_dir)\n",
        "else:\n",
        "    for fname in listdir(tmp_dir):\n",
        "        unlink(join(tmp_dir, fname))\n",
        "\n",
        "# create ctrl dir if non exitent\n",
        "ctrl_dir = join(args.logdir, 'cma')\n",
        "if not exists(ctrl_dir):\n",
        "    makedirs(ctrl_dir)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#                           Thread routines                                    #\n",
        "################################################################################\n",
        "def slave_routine(p_queue, r_queue, e_queue, p_index):\n",
        "    \"\"\" Thread routine.\n",
        "\n",
        "    Threads interact with p_queue, the parameters queue, r_queue, the result\n",
        "    queue and e_queue the end queue. They pull parameters from p_queue, execute\n",
        "    the corresponding rollout, then place the result in r_queue.\n",
        "\n",
        "    Each parameter has its own unique id. Parameters are pulled as tuples\n",
        "    (s_id, params) and results are pushed as (s_id, result).  The same\n",
        "    parameter can appear multiple times in p_queue, displaying the same id\n",
        "    each time.\n",
        "\n",
        "    As soon as e_queue is non empty, the thread terminate.\n",
        "\n",
        "    When multiple gpus are involved, the assigned gpu is determined by the\n",
        "    process index p_index (gpu = p_index % n_gpus).\n",
        "\n",
        "    :args p_queue: queue containing couples (s_id, parameters) to evaluate\n",
        "    :args r_queue: where to place results (s_id, results)\n",
        "    :args e_queue: as soon as not empty, terminate\n",
        "    :args p_index: the process index\n",
        "    \"\"\"\n",
        "    sys.stdout = sys.__stdout__\n",
        "    sys.stdout.write(\"hello\")\n",
        "    # init routine\n",
        "    #gpu = p_index % torch.cuda.device_count()\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # redirect streams\n",
        "    sys.stdout = open(join(tmp_dir, str(getpid()) + '.out'), 'a')\n",
        "    sys.stderr = open(join(tmp_dir, str(getpid()) + '.err'), 'a')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        r_gen = RolloutGenerator(args.logdir, device, time_limit)\n",
        "\n",
        "        while e_queue.empty():\n",
        "            if p_queue.empty():\n",
        "                sleep(.1)\n",
        "            else:\n",
        "                s_id, params = p_queue.get()\n",
        "                r_queue.put((s_id, r_gen.rollout(params)))\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#                Define queues and start workers                               #\n",
        "################################################################################\n",
        "p_queue = ctx.Queue()\n",
        "r_queue = ctx.Queue()\n",
        "e_queue = ctx.Queue()\n",
        "\n",
        "for p_index in range(num_workers):\n",
        "    ctx.Process(target=slave_routine, args=(p_queue, r_queue, e_queue, p_index)).start()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#                           Evaluation                                         #\n",
        "################################################################################\n",
        "def evaluate(solutions, results, rollouts=100):\n",
        "    \"\"\" Give current controller evaluation.\n",
        "\n",
        "    Evaluation is minus the cumulated reward averaged over rollout runs.\n",
        "\n",
        "    :args solutions: CMA set of solutions\n",
        "    :args results: corresponding results\n",
        "    :args rollouts: number of rollouts\n",
        "\n",
        "    :returns: minus averaged cumulated reward\n",
        "    \"\"\"\n",
        "    index_min = np.argmin(results)\n",
        "    best_guess = solutions[index_min]\n",
        "    restimates = []\n",
        "\n",
        "\n",
        "    for s_id in range(rollouts):\n",
        "        p_queue.put((s_id, best_guess))\n",
        "\n",
        "    print(\"Evaluating...\")\n",
        "\n",
        "    for _ in tqdm(range(rollouts)):\n",
        "        while r_queue.empty():\n",
        "            sleep(.1)\n",
        "        restimates.append(r_queue.get()[1])\n",
        "\n",
        "    return best_guess, np.mean(restimates), np.std(restimates)\n",
        "\n",
        "################################################################################\n",
        "#                           Launch CMA                                         #\n",
        "################################################################################\n",
        "controller = Controller(hp.vsize, hp.msize, hp.asize)  # dummy instance\n",
        "\n",
        "# define current best and load parameters\n",
        "cur_best = None\n",
        "ctrl_file = join(ctrl_dir, 'best.tar')\n",
        "print(\"Attempting to load previous best...\")\n",
        "if exists(ctrl_file):\n",
        "    state = torch.load(ctrl_file, map_location={'cuda:0': 'cpu'})\n",
        "    cur_best = - state['reward']\n",
        "    controller.load_state_dict(state['state_dict'])\n",
        "    print(\"Previous best was {}...\".format(-cur_best))\n",
        "\n",
        "parameters = controller.parameters()\n",
        "es = cma.CMAEvolutionStrategy(flatten_parameters(parameters),  # number of model parameters\n",
        "                              0.1,                                # initial standard deviation\n",
        "                              {'popsize': pop_size})               # population size\n",
        "\n",
        "epoch = 0\n",
        "log_step = 3\n",
        "while not es.stop():\n",
        "    if cur_best is not None and - cur_best > args.target_return:\n",
        "        print(\"Already better than target, breaking...\")\n",
        "        break\n",
        "\n",
        "    r_list = [0] * pop_size  # result list\n",
        "    solutions = es.ask()\n",
        "\n",
        "    # push parameters to queue\n",
        "    for s_id, s in enumerate(solutions):\n",
        "        for _ in range(n_samples):\n",
        "            p_queue.put((s_id, s))\n",
        "\n",
        "    # retrieve results\n",
        "    if args.display:\n",
        "        pbar = tqdm(total=pop_size * n_samples)\n",
        "\n",
        "    for _ in range(pop_size * n_samples):\n",
        "        while r_queue.empty():\n",
        "            sleep(.1)\n",
        "        r_s_id, r = r_queue.get()\n",
        "        r_list[r_s_id] += r / n_samples\n",
        "\n",
        "        if args.display:\n",
        "            pbar.update(1)\n",
        "\n",
        "    if args.display:\n",
        "        pbar.close()\n",
        "\n",
        "    es.tell(solutions, r_list)\n",
        "    es.disp()\n",
        "\n",
        "\n",
        "    # evaluation and saving\n",
        "    if epoch % log_step == log_step - 1:\n",
        "        best_params, best, std_best = evaluate(solutions, r_list)\n",
        "        print(\"Current evaluation: {}\".format(best))\n",
        "        if not cur_best or cur_best > best:\n",
        "            cur_best = best\n",
        "            print(\"Saving new best with value {}+-{}...\".format(-cur_best, std_best))\n",
        "            load_parameters(best_params, controller)\n",
        "            torch.save(\n",
        "                {'epoch': epoch,\n",
        "                 'reward': - cur_best,\n",
        "                 'state_dict': controller.state_dict()},\n",
        "                join(ctrl_dir, 'best.tar'))\n",
        "        if - best > args.target_return:\n",
        "            print(\"Terminating controller training with value {}...\".format(best))\n",
        "            break\n",
        "\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "es.result_pretty()\n",
        "e_queue.put('EOP')"
      ],
      "metadata": {
        "id": "Y7vhCBG6ypS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RolloutGenerator(object):\n",
        "    \"\"\" Utility to generate rollouts.\n",
        "\n",
        "    Encapsulate everything that is needed to generate rollouts in the TRUE ENV\n",
        "    using a controller with previously trained VAE and MDRNN.\n",
        "\n",
        "    :attr vae: VAE model loaded from mdir/vae\n",
        "    :attr mdrnn: MDRNN model loaded from mdir/mdrnn\n",
        "    :attr controller: Controller, either loaded from mdir/ctrl or randomly\n",
        "        initialized\n",
        "    :attr env: instance of the CarRacing-v0 gym environment\n",
        "    :attr device: device used to run VAE, MDRNN and Controller\n",
        "    :attr time_limit: rollouts have a maximum of time_limit timesteps\n",
        "    \"\"\"\n",
        "    def __init__(self, mdir, device, time_limit):\n",
        "        \"\"\" Build vae, rnn, controller and environment. \"\"\"\n",
        "        # Loading world model and vae\n",
        "        '''\n",
        "        vae_file, rnn_file, ctrl_file = \\\n",
        "            [join(mdir, m, 'best.tar') for m in ['vae', 'rnn', 'cma']]\n",
        "        '''\n",
        "\n",
        "        vae_file = []\n",
        "        vae_file = vae_file.append(join(mdir, 'vae', '002k.pth.tar'))\n",
        "        rnn_file = []\n",
        "        rnn_file = rnn_file.append(join(mdir, 'rnn', '001k.pth.tar'))\n",
        "        cma_file = []\n",
        "        cma_file = cma_file.append(join(mdir, 'cma', 'best.tar'))\n",
        "\n",
        "\n",
        "        assert exists(vae_file) and exists(rnn_file),\\\n",
        "            \"Either vae or mdrnn is untrained.\"\n",
        "\n",
        "        vae_state, rnn_state = [\n",
        "            torch.load(fname, map_location={'cuda:0': str(device)})\n",
        "            for fname in (vae_file, rnn_file)]\n",
        "\n",
        "        for m, s in (('VAE', vae_state), ('RNN', rnn_state)):\n",
        "            print(\"Loading {} at epoch {} \"\n",
        "                  \"with test loss {}\".format(\n",
        "                      m, s['epoch'], s['precision']))\n",
        "\n",
        "        self.vae = VAE(hp.vsize, 3).to(device)\n",
        "        self.vae.load_state_dict(vae_state['state_dict'])\n",
        "\n",
        "        self.rnn = RNN(hp.vsize, hp.asize, hp.msize).to(device)\n",
        "        self.rnn.load_state_dict(\n",
        "            {k.strip('_l0'): v for k, v in rnn_state['state_dict'].items()})\n",
        "\n",
        "        self.controller = Controller(hp.vsize, hp.msize, hp.asize).to(device)\n",
        "\n",
        "        # load controller if it was previously saved\n",
        "        if exists(cma_file):\n",
        "            cma_state = torch.load(cma_file, map_location={'cuda:0': str(device)})\n",
        "            print(\"Loading Controller with reward {}\".format(\n",
        "                cma_state['reward']))\n",
        "            self.controller.load_state_dict(cma_state['state_dict'])\n",
        "\n",
        "        self.env = gym.make('CarRacing-v2', render_mode='human')\n",
        "        self.device = device\n",
        "\n",
        "        self.time_limit = time_limit\n",
        "\n",
        "    def get_action_and_transition(self, obs, hidden):\n",
        "        \"\"\" Get action and transition.\n",
        "\n",
        "        Encode obs to latent using the VAE, then obtain estimation for next\n",
        "        latent and next hidden state using the MDRNN and compute the controller\n",
        "        corresponding action.\n",
        "\n",
        "        :args obs: current observation (1 x 3 x 64 x 64) torch tensor\n",
        "        :args hidden: current hidden state (1 x 256) torch tensor\n",
        "\n",
        "        :returns: (action, next_hidden)\n",
        "            - action: 1D np array\n",
        "            - next_hidden (1 x 256) torch tensor\n",
        "        \"\"\"\n",
        "        _, latent_mu, _ = self.vae(obs)\n",
        "        action = self.controller(latent_mu, hidden[0])\n",
        "        _, _, _, _, _, next_hidden = self.rnn(action, latent_mu, hidden)\n",
        "        return action.squeeze().cpu().numpy(), next_hidden\n",
        "\n",
        "    def rollout(self, params, render=False):\n",
        "        \"\"\" Execute a rollout and returns minus cumulative reward.\n",
        "\n",
        "        Load :params: into the controller and execute a single rollout. This\n",
        "        is the main API of this class.\n",
        "\n",
        "        :args params: parameters as a single 1D np array\n",
        "\n",
        "        :returns: minus cumulative reward\n",
        "        \"\"\"\n",
        "        # copy params into the controller\n",
        "        if params is not None:\n",
        "            load_parameters(params, self.controller)\n",
        "\n",
        "        obs = self.env.reset()\n",
        "\n",
        "        # This first render is required !\n",
        "        self.env.render()\n",
        "\n",
        "        hidden = [\n",
        "            torch.zeros(1, hp.msize).to(self.device)\n",
        "            for _ in range(2)]\n",
        "\n",
        "        cumulative = 0\n",
        "        i = 0\n",
        "        while True:\n",
        "            obs = transform(obs).unsqueeze(0).to(self.device)\n",
        "            action, hidden = self.get_action_and_transition(obs, hidden)\n",
        "            obs, reward, done, _ = self.env.step(action)\n",
        "\n",
        "            if render:\n",
        "                self.env.render()\n",
        "\n",
        "            cumulative += reward\n",
        "            if done or i > self.time_limit:\n",
        "                return - cumulative\n",
        "            i += 1"
      ],
      "metadata": {
        "id": "cc-SV0Ck__FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Test controller \"\"\"\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"logdir\" : 'ckpt'\n",
        "})\n",
        "\n",
        "cma_file = join(args.logdir, 'cma', 'best.tar')\n",
        "\n",
        "assert exists(cma_file),\\\n",
        "    \"Controller was not trained...\"\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "generator = RolloutGenerator(args.logdir, device, 1000)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generator.rollout(None)"
      ],
      "metadata": {
        "id": "udYcYcfL_V68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}